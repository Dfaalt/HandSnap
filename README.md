# HandSnap

A web application that can recognize hand gestures to perform actions such as taking screenshots and transferring files between devices. Built with **React (Vite)**, **TensorFlow\.js**, **MediaPipe Hands**, and **Flask** as the REST API.

> Demo (production): `https://hand-snap.vercel.app/`

---

## âœ¨ Features

* Real-time hand detection and gesture classification (currently 2 classes): `SS` (screenshot) and `transfer_SS` (send last screenshot).
* Automatic feedback when successful (flash, toast notification, sound) and clear error notifications.
* Screenshot saving and cross-device transfer via REST API.
* Control buttons for Start/Stop/Restart detection, plus open camera mode for receiving files.

---

## ğŸ§° Tech Stack

* **Frontend:** React + Vite, TensorFlow\.js, MediaPipe Hands
* **Backend:** Flask (REST API)
* **Build/Deploy:** Vercel (frontend), Railway/Render/Heroku (backend)

---

## ğŸ“¦ Project Structure

```
HandSnap/
â”œâ”€ public/
â”‚  â””â”€ model/                 # TFJS model files (model.json + shards)
â”œâ”€ src/
â”‚  â”œâ”€ assets/                # icons, sounds, static assets
â”‚  â”œâ”€ components/            # UI components (buttons, camera, controls)
â”‚  â”œâ”€ utils/                 # helpers (performanceLogger, gesture buffer), API client (Flask endpoints)
â”‚  â”œâ”€ App.jsx                # main app component
â”‚  â””â”€ main.jsx               # entry point
â”œâ”€ index.html
â”œâ”€ package.json
â”œâ”€ vite.config.js
â””â”€ README.md
```

---

## âœ… Prerequisites

* **Node.js** â‰¥ 18
* **Python** â‰¥ 3.10 (for backend)
* **Google Chrome** (recommended)
* Webcam + permission for **camera** & **screen capture**

---

## ğŸš€ Running the Frontend

1. **Clone & install**

```bash
git clone https://github.com/Dfaalt/HandSnap.git
cd HandSnap
npm install
```

2. **Place the model**

```
public/model/
  â”œâ”€ model.json
  â””â”€ group1-shard1ofN.bin ... group1-shardNofN.bin
```

3. **Environment configuration (optional)** Create `.env` file:

```
VITE_API_BASE_URL=http://localhost:5000
```

4. **Run dev server**

```bash
npm run dev
```

Open in browser: `http://localhost:5173`

---

## ğŸ Running the Backend (Flask)

1. **Create virtual environment**

```bash
python -m venv venv
venv\Scripts\activate   # Windows
source venv/bin/activate # macOS/Linux
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Run Flask server**

```bash
python app.py
```

Local URL: `http://localhost:5000`

---

## ğŸ® How to Use

1. Open the app in Chrome.
2. Click **Start Detection** and grant camera & screen capture permissions.
3. Perform gestures:

   * **SS** â†’ take a screenshot (flash + toast + sound).
   * **transfer\_SS** â†’ send screenshot (toast + animation + auto-download on receiver).
4. Additional controls:

   * **Restart Detection** â€” restart detection.
   * **Stop Detection** â€” stop camera & screen capture.
   * **Open Camera** â€” open receiver mode.

---

## âš™ï¸ Model Info

* **Input shape:** `[1, 10, 63]` â†’ 10 timesteps Ã— 21 landmarks Ã— (x,y,z)
* **Classes:** `SS`, `transfer_SS`
* **Cooldown:** 1.5 seconds (prevent repeated triggers)

---

## ğŸ§ª Performance Tips

* Use **WebGL** backend in TensorFlow\.js.
* Ensure proper lighting.
* Close heavy tabs in the browser.
* Ensure `requestAnimationFrame` is fully stopped before restarting detection.

---

## ğŸ©¹ Troubleshooting

* **Camera not detected:** check Chrome camera permissions.
* **Gesture misclassified:** keep hand stable, retrain model if needed.
* **Model failed to load:** ensure `public/model/` files exist.
* **CORS error:** enable Flask CORS, check `VITE_API_BASE_URL`.

---

## ğŸ› ï¸ Scripts

```bash
npm run dev       # run dev server
npm run build     # production build
npm run preview   # preview build locally
```

---

## ğŸ§± Roadmap

* Add more gesture variations
* Better mobile support
* User login & authentication

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create branch: `git checkout -b feat/new-feature`
3. Commit: `git commit -m "feat: commit message"`
4. Push & open Pull Request

---

## ğŸ“„ License

MIT

---

## ğŸ™Œ Credits

* TensorFlow\.js, MediaPipe Hands
* React & Vite community
